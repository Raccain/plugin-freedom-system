# DSP Architecture: GrooveScout

**CRITICAL CONTRACT:** This specification is immutable during Stages 1-4 implementation. Stage 1 Planning cannot proceed without this file. Stage 3 (DSP) implements this exact architecture.

**Generated by:** Stage 0 Research (research-planning-agent)
**Date:** 2026-02-20
**Referenced by:** Stage 1 (Planning), Stage 3 (DSP Implementation)
**Purpose:** DSP specification defining processing components, signal flow, and JUCE module usage

---

## Core Components

### Audio Buffer Recorder
- **JUCE Class:** Custom implementation using `juce::AudioBuffer<float>` + `std::atomic<bool>`
- **Purpose:** Accumulates incoming real-time audio blocks into a large pre-allocated recording buffer. Analysis can only run after sufficient audio has been captured. Recording is triggered by a capture mode flag set when the user presses Analyze.
- **Parameters Affected:** None (internal infrastructure)
- **Configuration:**
  - Pre-allocate recording buffer at `prepareToPlay()` for max expected length (e.g., 30 seconds at current sample rate)
  - Double-buffered: one buffer accumulates, swap atomically before analysis
  - `std::atomic<int> recordedSamples` tracks fill level
  - Recording begins immediately on `analyzeTriggered` flag set; if already recording from a prior session, the old buffer is used
  - Audio thread copies from `processBlock()` buffer — no allocation, no locking
  - Record stereo (mix to mono if needed), or keep stereo for better onset detection

### BPM Detection Engine
- **JUCE Class:** Custom implementation (onset strength signal + generalized autocorrelation). Alternatively: MiniBPM (single-file C++ library, MIT/GPL dual license)
- **Purpose:** Estimates tempo from accumulated audio buffer. Runs offline (not real-time) on background thread.
- **Parameters Affected:** `analyzeBPM`, `bpmMultiplier`
- **Configuration:**
  - Input: mono audio buffer, sample rate
  - Step 1: Compute onset strength signal (OSS) — energy change per frame, typically 512-sample hop
  - Step 2: Generalized autocorrelation of OSS: `GAC = IFFT(FFT(OSS^0.5))` — uses `juce::dsp::FFT`
  - Step 3: Peak-picking from lag range 300ms–1000ms (60–200 BPM)
  - Step 4: Score top candidates via cross-correlation with ideal pulse trains
  - Step 5: Apply `bpmMultiplier` (0.5x / 1x / 2x) to detected raw BPM
  - Output: float detectedBPM

### Key Detection Engine
- **JUCE Class:** Custom implementation (STFT chroma extraction + Krumhansl-Schmuckler profile matching). Uses `juce::dsp::FFT` for STFT.
- **Purpose:** Identifies the musical key from accumulated audio. Runs offline on background thread.
- **Parameters Affected:** `analyzeKey`
- **Configuration:**
  - Input: mono audio buffer, sample rate
  - Step 1: Compute short-time Fourier transform (STFT) with 4096-point FFT, 50% overlap, Hann window
  - Step 2: Build pitch class profile (PCP / chromagram): map spectral magnitude to 12 pitch classes by folding FFT bins into octave-independent bins
  - Step 3: Accumulate PCP across all frames → single 12-element vector
  - Step 4: Correlate PCP against Krumhansl-Schmuckler key profiles for all 24 keys (12 major + 12 minor)
  - Step 5: Key with highest Pearson correlation coefficient is detected key
  - Output: keyIndex (0–23), keyString (e.g., "F# minor")
  - Root chord MIDI derived from key: major triad (root, +4, +7 semitones) or minor triad (root, +3, +7)

### Band-Separated Onset Detector
- **JUCE Class:** `juce::dsp::IIR::Filter` (Butterworth bandpass, cascade of LP+HP), custom onset detector
- **Purpose:** Separate the accumulated audio into three frequency bands and detect onset events (hits) within each band to produce kick, snare, and hihat MIDI patterns.
- **Parameters Affected:** `kickSensitivity`, `kickFreqLow`, `kickFreqHigh`, `snareSensitivity`, `snareFreqLow`, `snareFreqHigh`, `hihatSensitivity`, `hihatFreqLow`, `hihatFreqHigh`, `analyzeKick`, `analyzeSnare`, `analyzeHihat`
- **Configuration:**
  - Three parallel bandpass filter chains (one per drum):
    - Kick: HP @ kickFreqLow, LP @ kickFreqHigh (default 40–120 Hz)
    - Snare: HP @ snareFreqLow, LP @ snareFreqHigh (default 200–8000 Hz)
    - Hihat: HP @ hihatFreqLow, LP @ hihatFreqHigh (default 5000–16000 Hz)
  - Each filter built as two cascaded 2nd-order IIR sections (Butterworth coefficients)
  - Per-band onset detection: compute RMS energy in short windows (e.g., 256-sample windows), detect large positive energy delta
  - Adaptive threshold per band: moving average of energy + N standard deviations, controlled by `*Sensitivity` parameter (lower sensitivity = higher threshold divisor, detects only strong hits)
  - Onset timing: sample index of detected peak → converted to quarter-note position using detected BPM
  - Onset strength → MIDI velocity (0–127, normalized from peak energy in band)
  - Constraint validation: if freqLow >= freqHigh for any band, clamp or swap during analysis setup (not in real-time)

### MIDI Pattern Assembler
- **JUCE Class:** `juce::MidiFile`, `juce::MidiMessageSequence`, `juce::MidiMessage`
- **Purpose:** Convert onset lists (timing + velocity per drum) into JUCE MIDI data structures. Convert key/root chord into a MIDI chord event. Write to temporary files for drag-and-drop.
- **Parameters Affected:** None (downstream from analysis)
- **Configuration:**
  - MIDI format: Type 0 (single track), 480 PPQ resolution
  - Drum notes (GM standard): Kick = 36 (C1), Snare = 38 (D1), Closed Hihat = 42 (F#1)
  - Root chord: pitches derived from key index. Note-on events at tick 0, duration 1 bar (1920 ticks at 480 PPQ)
  - Pattern length: round up to nearest whole bar based on detected BPM and recording length
  - Tempo event: embed detected BPM as MIDI tempo event (microseconds per beat)
  - Drag output: write `juce::MidiFile` to `juce::File::getSpecialLocation(juce::File::tempDirectory)`
  - File naming: `groovescout_kick.mid`, `groovescout_snare.mid`, `groovescout_hihat.mid`, `groovescout_chord.mid`
  - Files are overwritten on each new analysis

### MIDI File Drag-and-Drop System
- **JUCE Class:** `juce::DragAndDropContainer::performExternalDragDropOfFiles()`
- **Purpose:** Allow user to drag generated MIDI clip files from plugin UI to DAW timeline.
- **Parameters Affected:** None
- **Configuration:**
  - PluginEditor inherits from `juce::DragAndDropContainer` (or a child component does)
  - Each MIDI clip area has a `mouseDrag()` override
  - On drag: call `performExternalDragDropOfFiles({pathToMidiFile}, true)` where `true` = can move
  - The MIDI file must already exist on disk (written by MIDI Pattern Assembler after analysis)
  - Drag is only active if analysis has completed and the clip is available (clip existence flag)
  - Cross-DAW compatibility: tested pattern works in Ableton Live, Logic Pro, Reaper; Studio One may have issues (known JUCE forum issue)
  - Windows-specific: `performExternalDragDropOfFiles` uses `DoDragDrop` shell API — reliable on Windows

### Background Analysis Thread
- **JUCE Class:** `juce::Thread` (subclass with `run()` override)
- **Purpose:** Run the entire analysis pipeline off the audio thread. Cancellable at any time.
- **Parameters Affected:** All `analyze*` bool parameters (gating which sub-analyses run)
- **Configuration:**
  - Thread class: `GrooveScoutAnalyzer : public juce::Thread`
  - `run()` method checks `threadShouldExit()` after each major analysis step
  - Analysis steps in order: BPM detection → Key detection → Drum separation → MIDI assembly
  - Each step individually gated by corresponding `analyze*` bool
  - Progress reported via `std::atomic<float> analysisProgress` (0.0–1.0)
  - Completion reported via `std::atomic<bool> analysisComplete`
  - Error state via `std::atomic<int> analysisError` (0 = none, 1 = buffer too short, 2 = cancelled)
  - Thread priority: LOW (not real-time, analysis is batch)
  - Cancel: UI Cancel button calls `thread.stopThread(2000)` (2-second timeout)
  - Thread reuse: stop and restart for each new analysis

### Audio Passthrough
- **JUCE Class:** `juce::AudioBuffer<float>` (identity copy, no DSP)
- **Purpose:** GrooveScout is an analysis utility — audio passes through completely unchanged.
- **Parameters Affected:** None
- **Configuration:**
  - In `processBlock()`: do not modify the audio buffer
  - Simply copy samples to recording buffer (append to accumulation buffer)
  - Zero latency reported: `getLatencySamples()` returns 0
  - Bus config: stereo in, stereo out (effect plugin)

---

## Processing Chain

```
DAW Audio Track
       |
       v
 processBlock() [AUDIO THREAD]
       |
       +---> Audio Passthrough (unmodified audio → DAW output)
       |
       +---> Recording Buffer Accumulator
                 |
                 | [atomic flag: analyzeTriggered]
                 v
        [Background Thread - GrooveScoutAnalyzer::run()]
                 |
         [Read snapshots of recorded buffer + parameters]
                 |
        +--------+--------+--------+
        |        |        |        |
        v        v        v        v
      BPM      Key      Kick    Snare   Hihat
   Detection Detection  Band    Band    Band
       |        |        |       |       |
       |        |        +-------+-------+
       |        |              |
       |        |        Per-Band Onset
       |        |           Detection
       |        |              |
       v        v              v
    detectedBPM keyIndex    onset lists
                              (timing, velocity)
                 |
                 v
        MIDI Pattern Assembler
        (MidiFile + MidiMessageSequence)
                 |
        +--------+--------+--------+--------+
        |        |        |        |        |
        v        v        v        v        v
     kick.mid snare.mid hihat.mid chord.mid
        [written to temp directory]
                 |
                 v
     [atomic flag: analysisComplete]
                 |
                 v
     UI Timer Poll → update displays
                 |
                 v
     User drags MIDI clip
                 |
                 v
  performExternalDragDropOfFiles()
                 |
                 v
      DAW MIDI Track
```

**Routing notes:**
- Audio thread never touches analysis data (pure passthrough)
- Background thread reads a snapshot of recording buffer (safe copy or pointer swap)
- UI polls analysis state via juce::Timer (not direct callback from audio thread)
- MIDI files live on disk — drag only passes file paths, not data

---

## System Architecture

### Audio Capture / Recording System

**Strategy:** Continuous accumulation with user-triggered analysis

The plugin accumulates audio during normal playback (the user plays back their track, then hits Analyze). It does NOT require the user to do anything special before playing.

**Recording lifecycle:**
1. On `prepareToPlay()`: allocate recording buffer (configurable max duration, e.g., 30s × sampleRate × numChannels)
2. On `processBlock()`: if `isCapturing` flag is set, append incoming samples to recording buffer. If buffer full, wrap (circular) or stop (and flag "buffer full")
3. When Analyze pressed: set `analyzeTriggered` atomic flag, snapshot current `recordedSampleCount`
4. Background thread reads the accumulated buffer up to `recordedSampleCount`
5. On re-analyze: reset recording buffer, re-capture

**JUCE classes:**
- `juce::AudioBuffer<float>` - Recording buffer storage
- `std::atomic<int>` - `recordedSamples` count (audio thread writes, background thread reads)
- `std::atomic<bool>` - `isCapturing`, `analyzeTriggered`, `analysisComplete`

**Thread safety:**
- Audio thread only writes to recording buffer sequentially (no reads from background during capture)
- Before background thread reads: set `captureComplete` flag, stop appending
- Background thread reads a stable snapshot (either a copy or a pointer to the finalized portion)
- No mutexes needed if capture stops before analysis reads

**Minimum viable capture:**
- At least 4 bars needed for reliable BPM detection
- At least 8 bars recommended for key detection
- Display warning in UI if recorded length < 2 seconds

### MIDI Drag-and-Drop System

**Strategy:** Write MIDI to temp files, use `performExternalDragDropOfFiles()`

**File lifecycle:**
- MIDI files written to `juce::File::getSpecialLocation(juce::File::tempDirectory) / "GrooveScout/"`
- Directory created if it doesn't exist
- Files overwritten on each analysis
- Files NOT cleaned up on plugin close (temp OS cleanup handles this)

**JUCE classes:**
- `juce::File` - Path management
- `juce::FileOutputStream` - Write MIDI data
- `juce::MidiFile` - MIDI format serialization
- `juce::MidiMessageSequence` - MIDI event sequence
- `juce::DragAndDropContainer::performExternalDragDropOfFiles()` - Trigger OS drag

**DAW compatibility notes:**
- Ableton Live: Works (drag to MIDI track clip slot)
- Logic Pro: Works (drag to MIDI region)
- Reaper: Works
- Studio One: May have intermittent issues (known JUCE forum reports)
- FL Studio: Should work (file-based drag)
- Windows: Uses `DoDragDrop` shell API — widely supported

### State Persistence

**What state is saved:**
- APVTS parameters: all `kick/snare/hihat*`, `bpmMultiplier`, `analyze*` (automatic via APVTS)
- Custom state:
  - Last detected BPM (display on reopen)
  - Last detected key string
  - Whether analysis results are available (clip draggable)
  - MIDI file paths (to re-enable dragging after preset load)

**Serialization format:**
- APVTS: XML (automatic)
- Custom: ValueTree stored alongside APVTS state

```
<GrooveScoutState>
  <AnalysisResult bpm="120.5" key="F# minor" hasResults="1"/>
</GrooveScoutState>
```

**JUCE classes:**
- `juce::AudioProcessorValueTreeState` - parameter persistence
- `juce::ValueTree` - custom state
- `juce::MemoryBlock` - binary state serialization in `getStateInformation()`

**Restore behavior:**
- On restore: display last BPM/key values if saved
- MIDI clips: only draggable if MIDI files still exist in temp directory
- If MIDI files missing after restore: show "Re-analyze to generate clips" message

---

## Parameter Mapping

| Parameter ID | Type | Range | Component | Usage |
|---|---|---|---|---|
| `kickSensitivity` | Float | 0.0–1.0 | Band Onset Detector | Threshold control: `threshold = movingAvg + (1.0 - sensitivity) * stdDev * 4.0` |
| `kickFreqLow` | Float | 20–500 Hz | Band Onset Detector | HP filter cutoff for kick band |
| `kickFreqHigh` | Float | 50–1000 Hz | Band Onset Detector | LP filter cutoff for kick band |
| `snareSensitivity` | Float | 0.0–1.0 | Band Onset Detector | Same formula as kick, for snare band |
| `snareFreqLow` | Float | 100–2000 Hz | Band Onset Detector | HP filter cutoff for snare band |
| `snareFreqHigh` | Float | 1000–20000 Hz | Band Onset Detector | LP filter cutoff for snare band |
| `hihatSensitivity` | Float | 0.0–1.0 | Band Onset Detector | Same formula as kick, for hihat band |
| `hihatFreqLow` | Float | 1000–20000 Hz | Band Onset Detector | HP filter cutoff for hihat band |
| `hihatFreqHigh` | Float | 5000–20000 Hz | Band Onset Detector | LP filter cutoff for hihat band |
| `bpmMultiplier` | Choice | 0/1/2 (½x/1x/2x) | BPM Detection | Applied post-detection: `displayBPM = rawBPM * [0.5, 1.0, 2.0][index]` |
| `analyzeBPM` | Bool | true/false | Analysis Thread | Gates BPM detection step |
| `analyzeKey` | Bool | true/false | Analysis Thread | Gates key detection step |
| `analyzeKick` | Bool | true/false | Analysis Thread | Gates kick onset detection |
| `analyzeSnare` | Bool | true/false | Analysis Thread | Gates snare onset detection |
| `analyzeHihat` | Bool | true/false | Analysis Thread | Gates hihat onset detection |

---

## Algorithm Details

### BPM Detection via Onset Autocorrelation

**Algorithm:** Onset Strength Signal (OSS) + Generalized Autocorrelation

**Implementation notes:**

1. Mix stereo recording buffer to mono (average channels)
2. Frame the audio: 2048-sample windows, 512-sample hop (43ms frames at 48kHz)
3. Per-frame: compute RMS energy. Energy difference from previous frame = onset function value
4. Apply half-wave rectification (only positive energy increases count)
5. Accumulate OSS vector: one value per frame
6. Compute generalized autocorrelation:
   ```
   OSS_power = [oss[i]^0.5 for i in OSS]   // exponent 0.5 for generalized AC
   GAC = IFFT(|FFT(OSS_power)|^2)
   ```
7. Convert lag indices to BPM: `BPM = 60.0 * frameHopSamples / (lagIndex * sampleRate) * framesPerSecond`
8. Restrict to lag range [300ms, 1000ms] = [60 BPM, 200 BPM]
9. Peak-pick top 3 candidates from GAC
10. Score each candidate via cross-correlation with ideal pulse train at that BPM
11. Return highest-scoring candidate
12. Apply bpmMultiplier: `result = rawBPM * multiplierValue`

**JUCE FFT usage:**
- `juce::dsp::FFT fft(11)` for 2048-point FFT
- `fft.performRealOnlyForwardTransform(data)` for OSS FFT
- `fft.performRealOnlyInverseTransform(data)` for GAC (IFFT step)
- Use `juce::dsp::WindowingFunction` (Hann window) before FFT

**Alternative (lower risk):** MiniBPM library — single C++ file, no dependencies, drop-in BPM estimator. License: GPL-3 (acceptable for this project type) or commercial license.

### Key Detection via Chroma + Krumhansl-Schmuckler

**Algorithm:** STFT chromagram + profile correlation

**Implementation notes:**

1. Mix to mono, normalize amplitude
2. STFT: 4096-point FFT (`juce::dsp::FFT fft(12)`), 50% overlap (2048-sample hop), Hann window
3. Per-frame: compute magnitude spectrum |X[k]|
4. Map FFT bins to pitch classes (0–11 = C, C#, D, ..., B):
   ```
   For each bin k:
     freq = k * sampleRate / fftSize
     midi_pitch = 12 * log2(freq / 440.0) + 69  // A4 = MIDI 69
     pitch_class = round(midi_pitch) % 12
     chroma[pitch_class] += magnitude[k]
   ```
5. Accumulate chroma across all frames → 12-element PCP vector
6. Normalize PCP to unit length
7. Krumhansl-Schmuckler major key profile (Krumhansl 1990):
   `[6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88]`
8. Minor key profile:
   `[6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17]`
9. For each of 24 keys (12 major + 12 minor rotations):
   - Rotate the profile by key root index
   - Compute Pearson correlation coefficient between PCP and rotated profile
10. Key with highest correlation wins
11. Convert key index to string: root name + " major" or " minor"
12. Generate root chord MIDI: for major key root+4+7, for minor key root+3+7

**Pitch class to note name mapping:**
```
["C", "C#", "D", "D#", "E", "F", "F#", "G", "G#", "A", "A#", "B"]
```

### Band-Separated Onset Detection

**Algorithm:** Cascaded IIR bandpass → RMS energy onset detector with adaptive threshold

**Per-drum implementation:**

1. Validate frequency bounds: if freqLow >= freqHigh, log warning and skip that band
2. Design HP filter: `juce::dsp::IIR::Coefficients<float>::makeHighPass(sampleRate, freqLow, 0.707)` (Butterworth Q)
3. Design LP filter: `juce::dsp::IIR::Coefficients<float>::makeLowPass(sampleRate, freqHigh, 0.707)`
4. Apply in series to the entire recorded audio buffer (offline, not real-time)
5. Frame the filtered signal: 256-sample windows, 128-sample hop
6. Per-frame: compute RMS energy `E[n]`
7. Compute onset function: `O[n] = max(0, E[n] - E[n-1])` (half-wave rectified energy difference)
8. Adaptive threshold: `T[n] = mean(O[n-w..n]) + (1.0 - sensitivity) * 4.0 * std(O[n-w..n])` where w = 40 frames (~500ms window)
9. Peak detection: onset at frame n if `O[n] > T[n]` and `O[n]` is local maximum (suppress for next 10 frames = ~80ms)
10. Record onset time in samples
11. Convert sample offset to beat position: `beatPosition = (sampleOffset / sampleRate) * (detectedBPM / 60.0)`
12. Quantize to nearest 1/16th note for cleaner MIDI (optional, togglable in future)
13. Onset strength → velocity: `velocity = clamp(O[n] / peakO * 127, 1, 127)`

### MIDI File Assembly

**Algorithm:** Convert onset list to Standard MIDI File format

**Implementation notes:**

1. Create `juce::MidiMessageSequence seq`
2. Add tempo event: `juce::MidiMessage::tempoMetaEvent(microsPerBeat)` at tick 0
3. For each onset (drumType, beatPosition, velocity):
   - Convert beat position to MIDI ticks: `tick = round(beatPosition * pulsesPerQuarterNote)` (PPQ = 480)
   - Note on: `juce::MidiMessage::noteOn(1, midiNoteNum, velocity)` at tick
   - Note off: `juce::MidiMessage::noteOff(1, midiNoteNum, 0)` at tick + 60 (1/32nd note duration)
4. Sort sequence: `seq.updateMatchedPairs()`
5. Create `juce::MidiFile mf`; `mf.setTicksPerQuarterNote(480)`
6. `mf.addTrack(seq)`
7. Write: `juce::FileOutputStream fos(destFile); mf.writeTo(fos)`

**Root chord (Key MIDI):**
- Notes: [rootMidi + octaveOffset, root + interval1, root + interval2] in octave 4
- For F# minor root = 66 (F#4): [66, 69, 73]
- All three notes simultaneously, duration = 4 beats (1920 ticks)

---

## Integration Points

### Feature Dependencies

- **Audio Buffer Recorder** must complete capture before **Background Analysis Thread** begins
- **BPM Detection** must complete before **Band-Separated Onset Detection** (beat positions need BPM for quantization)
- **Key Detection** is independent of BPM — can run in parallel if desired (but run sequentially for simplicity)
- **Band-Separated Onset Detection** must complete before **MIDI Pattern Assembler**
- **MIDI Pattern Assembler** must complete before drag-and-drop clips are available
- **Analysis Thread** must be stopped before a new analysis is triggered

### Parameter Interactions

- `kickFreqLow` and `kickFreqHigh` interact: freqLow must always be < freqHigh. If the user sets them equal or inverted, the onset detector for that band is skipped with a warning.
- `bpmMultiplier` and BPM detection: multiplier is applied post-detection, so the underlying beat-tracking algorithm always runs in absolute BPM. The multiplier corrects for half-time / double-time detection errors.
- `kickSensitivity` / `snareSensitivity` / `hihatSensitivity` each independently scale the adaptive threshold for their band. There is no cross-band interaction.
- `analyzeBPM` gates whether BPM detection runs. If disabled but BPM is needed for quantization, onset times are stored as sample offsets only (no beat-relative MIDI).
- `analyzeKick`, `analyzeSnare`, `analyzeHihat` are independent: any combination can be enabled.

### Processing Order Requirements

1. **Audio capture** (audio thread, continuous): append blocks to recording buffer
2. **Analyze trigger** (UI thread): user presses button → `analyzeTriggered = true` → `isCapturing = false`
3. **Thread start** (message thread): start `GrooveScoutAnalyzer` thread
4. **BPM detection** (background thread): process full recorded buffer → `detectedBPM`
5. **Key detection** (background thread): process full recorded buffer → `keyIndex`, `keyString`
6. **Drum separation** (background thread, parallelizable): apply 3 bandpass filters, onset detect each band
7. **MIDI assembly** (background thread): convert all onsets + key to MIDI files on disk
8. **Completion notification** (background thread → message thread): set `analysisComplete` atomic flag
9. **UI update** (message thread Timer): poll atomic flags, update displays, enable drag

### Thread Boundaries

**Audio thread (`processBlock`):**
- Append audio samples to recording buffer via sequential `memcpy`
- Read `isCapturing` atomic flag (no allocation, no locks)
- Write `recordedSamples` atomic counter
- Zero-latency audio passthrough

**Message thread (UI events):**
- Handle Analyze/Cancel button clicks
- Set atomic flags: `analyzeTriggered`, `cancelRequested`
- Start/stop `GrooveScoutAnalyzer` thread
- Poll analysis state via `juce::Timer` (60ms interval)
- Update BPM display, key display labels
- Handle MIDI clip mouse-drag events → `performExternalDragDropOfFiles()`

**Background thread (`GrooveScoutAnalyzer::run()`):**
- Read full recording buffer (after capture is complete — no concurrent writes)
- Run BPM, key, drum separation, MIDI assembly
- Check `threadShouldExit()` between each major step
- Write MIDI files to temp directory
- Set `analysisComplete` or `analysisCancelled` atomics when done

**Communication mechanisms:**
- `std::atomic<bool>`: `isCapturing`, `analyzeTriggered`, `analysisComplete`, `analysisCancelled`
- `std::atomic<int>`: `recordedSamples`, `analysisProgress` (as percentage 0–100)
- No mutexes required (capture stops before read begins — no concurrent access)
- MIDI file paths communicated via `std::atomic<bool>` clip-available flags (one per clip type)

---

## Implementation Risks

### Audio Buffer Recording

**Complexity:** MEDIUM

**Risk Level:** MEDIUM

**Risk factors:**
1. Variable block sizes in `processBlock()`: buffer must handle any block size (32–4096 samples)
2. Memory allocation: recording buffer must be pre-allocated at `prepareToPlay()`, cannot allocate in `processBlock()`
3. Sample rate changes: buffer must be re-allocated on sample rate change
4. Buffer overflow: user may not press Analyze for a long time — need circular buffer or a max-length cap
5. Thread safety: audio thread writes, background thread reads — needs careful handoff protocol

**Alternative approaches:**
1. **Circular buffer with mutex:** Simpler to manage overflow, but mutex in audio thread is bad practice
2. **Stop recording when buffer full:** Pre-allocate for max duration (30s), stop accumulating after that. Simple and safe.
3. **User-initiated capture (Arm → Play → Analyze):** Add "Arm" button that starts capture. Cleaner but extra UX step.

**Fallback architecture:**
- If buffer management proves problematic: use fixed max duration (30s) with simple stop-when-full behavior and a UI indicator showing "Recording: X / 30s"
- If pre-allocation at full sample rate is too large: record at reduced sample rate for key/BPM (key detection and BPM only need mono at 22kHz for example)

**Mitigation strategy:**
1. Pre-allocate at `prepareToPlay()` — max 30s × sampleRate × channels
2. Use `std::atomic<int> recordedSamples` for sample count (lock-free)
3. Set `isCapturing = false` before background thread reads buffer
4. Document max recording length in UI

### BPM Detection

**Complexity:** HIGH

**Risk Level:** MEDIUM

**Risk factors:**
1. Autocorrelation implementation requires FFT — non-trivial pipeline
2. Half-time / double-time ambiguity is a known problem (mitigated by bpmMultiplier parameter)
3. Complex recordings (polyrhythm, tempo changes, intro silence) degrade accuracy
4. Custom implementation from scratch is time-intensive

**Alternative approaches:**
1. **MiniBPM library:** Single C++ file, GPL-3 licensed, no external dependencies. Just include `MiniBPM.cpp` and `MiniBPM.h`. Trade-off: less control, GPL licensing.
2. **Simple autocorrelation on raw audio:** Simpler than OSS-based approach, less accurate. Good for pure drum loops.
3. **BTrack library:** More complete beat tracking with beat prediction. Requires libsamplerate + FFTW or KissFFT (external deps).

**Fallback architecture:**
- **Primary:** Custom OSS + generalized autocorrelation using `juce::dsp::FFT`
- **Fallback 1:** MiniBPM drop-in (if custom implementation has accuracy problems)
- **Fallback 2:** Expose BPM as a manual input (user types it) if detection is unreliable

**Mitigation strategy:**
1. Build OSS + autocorrelation as a self-contained class, unit test with known-tempo audio
2. MiniBPM is a low-risk fallback that can be dropped in within an hour
3. Test with both isolated drum loops and full mixes

### Key Detection

**Complexity:** HIGH

**Risk Level:** MEDIUM

**Risk factors:**
1. Chromagram computation requires STFT + bin-to-pitch mapping — moderately complex
2. Krumhansl-Schmuckler profiles are hardcoded constants (straightforward once understood)
3. Accuracy degrades on heavily processed audio, atonal music, or audio with strong bass (kick drum energy bleeds into low pitch classes)
4. Enharmonic equivalents (F# = Gb): use sharps by convention, may not match user expectation

**Alternative approaches:**
1. **External library (Essentia):** Very accurate, but Essentia is a large C++ library with many dependencies — not practical for a plugin
2. **Simplified chroma (comb filter bank):** Use 12 comb filters tuned to pitch classes instead of STFT. Simpler but less accurate.
3. **Skip key detection entirely:** Reduce scope if key detection proves too unreliable on full mixes

**Fallback architecture:**
- **Primary:** STFT chromagram + Krumhansl-Schmuckler
- **Fallback 1:** Comb filter bank approach (simpler, faster, less accurate)
- **Fallback 2:** Display "Key: Unknown" and omit root chord clip if key detection is removed

**Mitigation strategy:**
1. Implement Krumhansl-Schmuckler as a standalone function with hardcoded profiles (well-documented algorithm)
2. Test on known audio with ground-truth keys before integration
3. Apply pre-processing: high-pass filter above 100Hz before chroma to reduce kick drum contamination

### Band-Separated Onset Detection

**Complexity:** MEDIUM

**Risk Level:** MEDIUM

**Risk factors:**
1. Snare band (200–8000 Hz) overlaps heavily with kick harmonics and melodic content — cross-contamination on full mixes
2. Hihat band (5–16 kHz) picks up hi-frequency elements of synths, guitars, cymbals
3. Onset threshold tuning across different musical styles is hard to get right
4. Detection on full mixes (not isolated drums) is fundamentally imprecise

**Alternative approaches:**
1. **Simple energy threshold (no adaptive):** Simpler but fails for tracks with inconsistent dynamics
2. **Spectral flux onset detection:** More sophisticated than energy-based, uses complex spectrum for better precision
3. **Accept imperfect accuracy:** Document that the tool works best on drum-heavy tracks or isolated drum loops

**Fallback architecture:**
- **Primary:** Band-filtered RMS energy onset with adaptive threshold
- **Fallback 1:** Spectral flux within band (replace RMS energy with spectral flux if energy approach is too noisy)
- **Fallback 2:** Reduce sensitivity default, add documentation that full mixes produce noisier results

**Mitigation strategy:**
1. Use adaptive thresholds (not fixed) to handle different energy levels
2. Test on drum loops first, then full mixes
3. Apply minimum inter-onset interval (80ms) to suppress double-triggers
4. Tune default sensitivity values during testing

### MIDI Drag-and-Drop

**Complexity:** MEDIUM

**Risk Level:** HIGH

**Risk factors:**
1. `performExternalDragDropOfFiles()` behavior varies across DAWs
2. Plugin editor is embedded in DAW window — drag must escape plugin frame to reach DAW timeline
3. Known Ableton-specific issues with `performExternalDragDropOfFiles()` after certain UI scenarios (JUCE forum documented)
4. Windows vs. Mac: both supported in JUCE, but behaviors differ slightly
5. Plugin UI embedded in WebView: drag events from HTML elements must be routed to JUCE C++ layer

**Alternative approaches:**
1. **Copy-to-clipboard:** Place MIDI file path or raw MIDI data in clipboard, user pastes in DAW. No drag required. Lower UX but more reliable.
2. **Show MIDI file path in UI:** Allow user to navigate to the temp folder and drag the file themselves. Fallback-safe but poor UX.
3. **JUCE DragAndDropContainer (internal):** Different class for dragging between JUCE components — NOT applicable for DAW integration (need file system drag).

**Fallback architecture:**
- **Primary:** `performExternalDragDropOfFiles()` with temporary .mid files
- **Fallback 1:** Export button writes MIDI file to user-chosen path (file dialog)
- **Fallback 2:** Both drag AND export button (belt-and-suspenders approach)

**Mitigation strategy:**
1. Write MIDI to disk FIRST, then enable drag (file must exist before drag)
2. Use `mouseDrag()` on component rather than `mouseDown()` to avoid accidental triggers
3. Add minimum drag distance before initiating `performExternalDragDropOfFiles()`
4. Test in Ableton Live, Logic Pro, Reaper, FL Studio early
5. Consider providing export-to-file as backup for problematic DAWs

### Background Thread Analysis

**Complexity:** MEDIUM

**Risk Level:** LOW

**Risk factors:**
1. Thread cancellation mid-analysis must clean up state correctly
2. Starting a new analysis while the previous one is still running → potential race condition
3. Thread lifetime management in JUCE plugin (thread must stop before plugin destructor)

**Alternative approaches:**
1. **`juce::ThreadPool`:** Use a thread pool instead of a dedicated thread. More flexible but more complex.
2. **`juce::MessageManager::callAsync()`:** For very short analysis tasks. Not suitable here (analysis is seconds-long).

**Fallback architecture:**
- This component is well-understood in JUCE — fallback not needed
- Pattern is: `subclass juce::Thread`, check `threadShouldExit()` in loop, call `stopThread()` in destructor

**Mitigation strategy:**
1. Always call `thread.stopThread(2000)` in plugin destructor
2. Check `threadShouldExit()` after EVERY major analysis step (not just in inner loops)
3. Mutex-protect the "is running" flag to prevent double-start

### Overall Project Risk

**Overall complexity:** HIGH

- Multiple novel algorithms (BPM autocorrelation, chromagram key detection, adaptive onset detection)
- Complex multi-threaded architecture (audio capture + background analysis + UI interaction)
- MIDI file drag-and-drop across DAW boundary (known reliability issues)
- Offline analysis of variable-length audio (not standard real-time DSP)

**Highest risk component:** MIDI Drag-and-Drop
- Represents ~35% of cross-platform testing effort
- Known DAW-specific incompatibilities
- Embedding in plugin UI makes mouse event routing complex

**Second highest risk:** BPM + Key Detection accuracy on full mixes
- Full mix BPM detection is inherently harder than isolated drums
- Key detection accuracy on complex mixes is limited by chroma contamination

**Recommended approach:**
1. Phase 1: Build audio capture + passthrough (validate buffer architecture)
2. Phase 2: Implement BPM detection (test with isolated drum loops)
3. Phase 3: Implement key detection (test with known-key audio)
4. Phase 4: Implement drum onset detection (test accuracy vs. expected MIDI)
5. Phase 5: Implement MIDI file assembly + drag-and-drop (test in Ableton, Logic, Reaper)
6. Phase 6: UI integration and polish

---

## Architecture Decisions

### Decision: Offline Analysis (Not Real-Time)

**Decision:** Analysis runs once on a recorded buffer, triggered by user button press. Not continuous/real-time analysis.

**Rationale:**
- BPM and key detection algorithms require long time windows to be accurate (several seconds minimum)
- Onset detection benefits from the full recording context (adaptive threshold calibration)
- Offline processing has no CPU budget constraints — can use more intensive algorithms
- User workflow: "play the loop, then analyze" is natural for production context

**Alternatives considered:**
1. **Real-time BPM tracking (live tap/follow):** Would require different algorithm (e.g., beat prediction). More complex, less accurate for key detection. Rejected: key detection cannot work in real-time.
2. **Load audio file directly:** Require user to browse to an audio file. Simpler but not the plugin paradigm — plugin needs to work on any track in the DAW.

**Tradeoffs accepted:**
- User must play back audio before pressing Analyze (extra workflow step)
- Analysis results are based on what was recorded (may miss parts of the track not yet played)

### Decision: Use JUCE dsp::FFT for All Frequency Analysis

**Decision:** Use `juce::dsp::FFT` (from `juce_dsp` module) for all spectral analysis (BPM autocorrelation, chroma computation).

**Rationale:**
- No external FFT dependencies (FFTW, KissFFT) required
- `juce::dsp::FFT` is well-tested and already available in the JUCE ecosystem
- Avoids licensing complications
- Power-of-2 FFT sizes sufficient for all use cases

**Alternatives considered:**
1. **FFTW:** Fastest FFT available, but requires separate linking, licensing (GPL or commercial)
2. **KissFFT:** Lightweight, but introduces an external dependency for marginal gain
3. **Essentia:** Full-featured MIR library but enormous dependency for a plugin

**Tradeoffs accepted:**
- `juce::dsp::FFT` is not the fastest FFT available, but for offline analysis this is irrelevant

### Decision: File-Based MIDI Drag-and-Drop (Not Data-Based)

**Decision:** Write MIDI to `.mid` files in temp directory, drag the files using `performExternalDragDropOfFiles()`.

**Rationale:**
- DAWs expect file system objects when receiving MIDI drag from external sources
- JUCE has no built-in mechanism for passing raw MIDI data between applications
- Temporary files are standard practice (Ableton's own Pack examples do this)
- File-based approach works on both Windows and macOS

**Alternatives considered:**
1. **Clipboard with raw MIDI data:** Not universally supported by DAWs for MIDI paste
2. **Inter-process communication:** Too complex, DAW-specific protocols

### Decision: Stereo Input + Stereo Output (Standard Effect Bus)

**Decision:** Plugin declared as stereo effect (stereo in, stereo out) even though it passes audio through unchanged.

**Rationale:**
- Allows placement on any track in the DAW (mono, stereo, both)
- Analysis can mix down to mono internally if needed
- Does not require special instrument channel configuration

**JUCE bus config:**
```cpp
AudioProcessor(BusesProperties()
    .withInput("Input", juce::AudioChannelSet::stereo(), true)
    .withOutput("Output", juce::AudioChannelSet::stereo(), true))
```

### Decision: bpmMultiplier as Post-Detection Correction

**Decision:** `bpmMultiplier` is applied after BPM detection, not fed into the algorithm.

**Rationale:**
- Half-time / double-time errors are the most common failure mode of autocorrelation BPM detection
- User can hear the result and correct: if it detects 80 BPM but the track is 160, use 2x
- This is simpler and more robust than trying to constrain the algorithm

---

## Special Considerations

### Thread Safety
- Audio thread: only `std::atomic` reads/writes (no locks, no allocation)
- Recording buffer: written only by audio thread during capture; read only by background thread after `isCapturing = false`
- Analysis state (BPM result, key string, MIDI file paths): set by background thread, read by message thread via atomic flags + message thread callback
- `analysisComplete` atomic: background thread sets, message thread reads in Timer callback
- No mutex required in normal operation path

### Performance
- Analysis is offline: no real-time CPU budget concerns
- Audio passthrough: near-zero CPU (memcpy only)
- Recording buffer append: O(n) per block where n = block size — negligible
- FFT analysis (background thread): full 30s at 48kHz = ~1.4M samples. With 4096-point FFT at 50% overlap = ~680 FFT operations per analysis. At ~0.1ms per FFT, total = ~68ms per component. Acceptable.
- IIR filtering of recording buffer: 3 bands × 1.4M samples = fast (a few hundred milliseconds total)
- Total analysis time estimate: 1–5 seconds for a 30-second recording

### Denormal Protection
- Analysis runs on background thread — denormals are less critical than in real-time audio thread
- Apply `juce::ScopedNoDenormals` at the start of `processBlock()` for the passthrough path
- IIR filter state during offline analysis: reset filter state before processing each band to avoid state contamination

### Sample Rate Handling
- Recording buffer reallocated in `prepareToPlay()` on sample rate change
- All frequency-dependent calculations (FFT bin mapping, filter coefficients) use `currentSampleRate` stored at `prepareToPlay()` time
- Background thread receives sample rate as a parameter, not via live JUCE API (thread safety)

### Latency
- Audio passthrough: zero latency (`getLatencySamples()` returns 0)
- Analysis latency: several seconds (offline, not reported to host)
- No latency compensation needed

### Frequency Constraint Validation
- For each band (kick, snare, hihat): validate `freqLow < freqHigh` at the start of analysis setup
- If constraint violated: skip that band's analysis, log a warning to the analysis result
- Parameter ranges in APVTS partially prevent this (overlapping ranges), but user may still set them to boundary values

---

## Research References

### Professional Plugins Researched

1. **Mixed In Key (v11)**
   - Industry leader in key + BPM detection for DJs and producers
   - Reports 95%+ accuracy on key detection for clean music
   - Uses proprietary algorithm (not published), but based on chroma-profile methods
   - Observation: works best on full songs, not just loops

2. **Traktor Pro (Native Instruments)**
   - Built-in BPM and key detection
   - 74% key detection accuracy (vs. Mixed In Key's 95%) per published comparison
   - Observation: autocorrelation-based BPM is standard, key detection varies widely in quality

3. **Serato DJ / Serato Studio**
   - Offers per-stem analysis (drums, bass, melody) in newer versions
   - Drag-to-session feature in Serato Studio is conceptually similar to GrooveScout
   - Observation: the "drag MIDI pattern" workflow is underserved in DAW plugin market

4. **Fadr (v6.0, "World's First Drum Separator")**
   - Separates kick, snare, hihat from full mixes using ML-based stem separation
   - Observation: ML approach is far superior for full mixes but requires trained models — too complex for this plugin
   - GrooveScout should document that band-based separation works best on drum-heavy tracks

5. **iZotope RX (Dialog Isolation / Music Rebalance)**
   - Uses deep learning for source separation
   - Observation: confirms that bandpass-based separation is a simplification — set realistic user expectations in documentation

### JUCE Documentation & Classes

- **`juce::dsp::FFT`**: module `juce_dsp`. Forward and inverse FFT. `fft.performRealOnlyForwardTransform()`. Power of 2 sizes. Used for: OSS autocorrelation, STFT chroma.
- **`juce::dsp::WindowingFunction`**: module `juce_dsp`. Hann/Blackman/Hamming windows. Applied to FFT input frames. `window.multiplyWithWindowingTable(data, size)`.
- **`juce::dsp::IIR::Coefficients`**: module `juce_dsp`. Factory methods `makeHighPass()`, `makeLowPass()`. Returns `ReferenceCountedObjectPtr`. Used for bandpass construction.
- **`juce::dsp::IIR::Filter`**: module `juce_dsp`. Stateful single-channel IIR filter. Use `reset()` before offline processing. `process(ProcessContext)` or per-sample via `processSample()`.
- **`juce::MidiFile`**: module `juce_audio_basics`. Write standard MIDI files. `setTicksPerQuarterNote()`, `addTrack()`, `writeTo(OutputStream)`.
- **`juce::MidiMessageSequence`**: module `juce_audio_basics`. Container for MIDI events. `addEvent()`, `updateMatchedPairs()`.
- **`juce::MidiMessage`**: module `juce_audio_basics`. Factory methods: `noteOn()`, `noteOff()`, `tempoMetaEvent()`.
- **`juce::Thread`**: module `juce_core`. Override `run()`. `startThread()`, `stopThread()`, `threadShouldExit()`. Used for analysis thread.
- **`juce::DragAndDropContainer::performExternalDragDropOfFiles()`**: module `juce_gui_basics`. Static method. Takes `juce::StringArray` of file paths. Triggers OS-level file drag. Called from `mouseDrag()` on a component.
- **`juce::File::getSpecialLocation(juce::File::tempDirectory)`**: module `juce_core`. Returns platform temp directory path.
- **`juce::FileOutputStream`**: module `juce_core`. Write bytes to file. Used with `MidiFile::writeTo()`.
- **`juce::AudioBuffer<float>`**: module `juce_audio_basics`. Main audio buffer. Pre-allocated recording buffer.
- **`juce::AudioProcessorValueTreeState`**: module `juce_audio_processors`. APVTS for parameter management and persistence.
- **`juce::Timer`**: module `juce_events`. Periodic message-thread callback. Used to poll analysis completion state and update UI.

### JUCE Critical Patterns from juce8-critical-patterns.md

- **Pattern 1 (CMake):** `juce_generate_juce_header()` required after `target_link_libraries()` — apply to GrooveScout
- **Pattern 4 (Bus Config):** Effect plugin: stereo in + stereo out in constructor `BusesProperties` — confirmed for GrooveScout
- **Pattern 5 (Threading):** Never call audio code from UI thread — use atomic flags for Analyze button communication
- **Pattern 17 (juce::dsp API):** All `juce::dsp::` components use `prepare(ProcessSpec)` + `process(ProcessContext)` pattern — apply to IIR filters

**Required modules:**
- `juce_audio_basics` — AudioBuffer, MidiFile, MidiMessageSequence, MidiMessage
- `juce_audio_processors` — AudioProcessorValueTreeState, AudioProcessor
- `juce_dsp` — FFT, WindowingFunction, IIR filters
- `juce_core` — Thread, File, FileOutputStream, Timer
- `juce_gui_basics` — DragAndDropContainer (for performExternalDragDropOfFiles)
- `juce_gui_extra` — WebBrowserComponent (if WebView UI used)

### Technical Resources

- Streamlined Tempo Estimation Based on Autocorrelation (ISMIR 2004) — algorithm foundation
- Krumhansl, C.L. (1990). *Cognitive foundations of musical pitch*. Oxford University Press. — Key profiles source
- MiniBPM library (Breakfast Quay): https://github.com/breakfastquay/minibpm — Drop-in BPM estimator fallback
- BTrack (Adam Stark, QMUL): https://github.com/adamstark/BTrack — Alternative beat tracker
- Real-time drums transcription with characteristic bandpass filtering (Academia.edu) — Drum separation methodology
- JUCE forum: https://forum.juce.com/t/can-one-drag-and-drop-midi-from-a-juce-plug-in-to-the-daw-timeline/27816 — MIDI drag-and-drop reference

---

## Notes

- GrooveScout is architecturally unique in this plugin system: it is the first plugin to run offline analysis on recorded audio, the first to use background threading for long-running computation, and the first to produce MIDI output (drag-and-drop) rather than audio.
- The WebView UI (if used) will need native function calls for: triggering analysis (Analyze/Cancel buttons), receiving analysis results (BPM display, key display), and initiating MIDI drags. These cannot use standard APVTS parameter binding since they are non-parameter actions.
- Consider using `juce::WebBrowserComponent`'s native function bridge (`getNativeFunction()`) for the Analyze button trigger, rather than an APVTS bool parameter, to get clean action semantics.
- The analysis result display (BPM number, key text) can be updated by the plugin calling a JS function via `webView->evaluateJavascript()` after the analysis completes.
- The BPM "click to set project tempo" feature requires `AudioPlayHead::CurrentPositionInfo` — specifically, the host must support `setCurrentPlaybackSamplePosition` or the equivalent tempo-setting API. In JUCE, this requires `AudioProcessor::getPlayHead()` and casting to host-specific interface. This feature may not be universally supported across all DAWs and should be implemented as best-effort with a clear UI fallback.
